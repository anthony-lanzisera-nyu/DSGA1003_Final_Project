{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nylaennels/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nylaennels/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('/Users/nylaennels/Desktop/train.csv')\n",
    "dev = pd.read_csv('/Users/nylaennels/Desktop/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id  user_id  prod_id  rating  label        date  \\\n",
       "0      0      923        0     3.0      1  2014-12-08   \n",
       "1      1      924        0     3.0      1  2013-05-16   \n",
       "2      2      925        0     4.0      1  2013-07-01   \n",
       "3      3      926        0     4.0      1  2011-07-28   \n",
       "4      4      927        0     4.0      1  2010-11-01   \n",
       "\n",
       "                                              review  \n",
       "0  The food at snack is a selection of popular Gr...  \n",
       "1  This little place in Soho is wonderful. I had ...  \n",
       "2  ordered lunch for 15 from Snack last Friday.  ...  \n",
       "3  This is a beautiful quaint little restaurant o...  \n",
       "4  Snack is great place for a  casual sit down lu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "for i in range(len(raw_train)):\n",
    "    tokens.append(word_tokenize(raw_train['review'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "tokens_filt = tokens.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokens_filt[w][i].lower() in stop_words:\n",
    "            tokens_filt[w].remove(tokens_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = ['?','.','!','(',')',',','...',';','''''','\"\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokens_filt[w][i] in punct:\n",
    "            tokens_filt[w].remove(tokens_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        tokens_filt[w][i] = (ps.stem(tokens_filt[w][i]))\n",
    "        del count[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of unlinked words (for vectorizer)\n",
    "unlinked_train = []\n",
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        unlinked_train.append(tokens_filt[w][i])\n",
    "        del count[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=raw_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train['cleaned_review'] = tokens_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(raw_train['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covnert column from list type to str type\n",
    "for i in range(len(df)): \n",
    "    df['cleaned_review'][i]=\" \".join(df['cleaned_review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tf-idf vectorizer\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(df['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dta = dev['review'] #use dev file as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = vectorizer.transform(test_dta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize baseline model & make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, loss='log', max_iter=50)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a classifier \n",
    "sgd = SGDClassifier(loss='log',penalty= 'l2', max_iter= 50,\n",
    "                                             alpha= 0.00001,fit_intercept= True)\n",
    "# Fit the classifier \n",
    "sgd.fit(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics = sgd.predict(test_vectors)\n",
    "predics_prob = sgd.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = dev['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - BEFORE UPSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the prediction probabilites of the postive class\n",
    "predics_prob_ones = []\n",
    "for i in range(len(predics_prob)):\n",
    "    predics_prob_ones.append(predics_prob[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_prob_ones = np.array(predics_prob_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, AUC-ROC, AP\n",
    "acc_raw = sklearn.metrics.accuracy_score(test_targets, predics, normalize=True)\n",
    "roc_raw = sklearn.metrics.roc_auc_score(test_targets,predics_prob_ones)\n",
    "ap_raw = sklearn.metrics.average_precision_score(test_targets,predics_prob_ones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.207655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics\n",
       "accuracy          0.898240\n",
       "AUC-ROC           0.714675\n",
       "AP                0.207655"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_raw = [acc_raw,roc_raw,ap_raw]\n",
    "metrics_raw = pd.DataFrame(metrics_raw, index=['accuracy','AUC-ROC','AP'], columns=['Baseline_Metrics'])\n",
    "metrics_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-sample - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = raw_train.drop(columns=['ex_id','user_id','prod_id','rating','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamp = SMOTE(random_state=5)\n",
    "samp_train,samp_targ = upsamp.fit_resample(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using up-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samp_train_vectors = vectorizer.transform(samp_df['cleaned_review'])\n",
    "sgd.fit(samp_train,samp_targ)\n",
    "samp_predics = sgd.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using predict_proba for probability scores for metrics\n",
    "y_score = sgd.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - AFTER SMOTE UPSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate probablity predictions for the positive class\n",
    "predics_prob_1 = []\n",
    "for i in range(len(y_score)):\n",
    "    predics_prob_1.append(y_score[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_SMOTE = sklearn.metrics.accuracy_score(test_targets, samp_predics, normalize=True)\n",
    "roc_SMOTE = sklearn.metrics.roc_auc_score(test_targets,predics_prob_1)\n",
    "ap_SMOTE = sklearn.metrics.average_precision_score(test_targets,predics_prob_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_upsamp = [acc_SMOTE,roc_SMOTE,ap_SMOTE]\n",
    "metric_up = pd.DataFrame(metrics_upsamp, columns=['Upsampled_no_tuning'], index=['accuracy','AUC-ROC','AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "      <th>Upsampled_no_tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898240</td>\n",
       "      <td>0.662648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714675</td>\n",
       "      <td>0.693540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.207655</td>\n",
       "      <td>0.188034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics  Upsampled_no_tuning\n",
       "accuracy          0.898240             0.662648\n",
       "AUC-ROC           0.714675             0.693540\n",
       "AP                0.207655             0.188034"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics_raw,metric_up],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - using SMOTE upsampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_grid = [25,100,250,500,750,1000,1250,1500,2000]\n",
    "alpha_grid = [0.000001,0.00005,0.0001,0.0005,0.001,0.005,0.01,0.1,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_iter = []\n",
    "tun_alpha = []\n",
    "tun_acc = []\n",
    "tun_roc = []\n",
    "tun_ap = []\n",
    "\n",
    "for i in range(0,9):\n",
    "    sgd_tun = SGDClassifier(loss='log',penalty='l2',max_iter=max_iter_grid[i], alpha=alpha_grid[i],fit_intercept=True)\n",
    "    sgd_tun.fit(samp_train,samp_targ)\n",
    "    predics_tun = sgd_tun.predict(test_vectors)\n",
    "    proba_tun = sgd_tun.predict_proba(test_vectors)\n",
    "    \n",
    "    tun_iter.append(max_iter_grid[i])\n",
    "    tun_alpha.append(alpha_grid[i])\n",
    "    \n",
    "    predics_prob_tun = []\n",
    "   \n",
    "    for i in range(len(proba_tun)):\n",
    "        predics_prob_tun.append(proba_tun[i][1])\n",
    "    \n",
    "    tun_acc.append(sklearn.metrics.accuracy_score(test_targets, predics_tun, normalize=True))\n",
    "    tun_roc.append(sklearn.metrics.roc_auc_score(test_targets,predics_prob_tun))\n",
    "    tun_ap.append(sklearn.metrics.average_precision_score(test_targets,predics_prob_tun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics from first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_tun = list(zip(tun_iter,tun_alpha,tun_acc,tun_roc,tun_ap))\n",
    "metrics_df_tun = pd.DataFrame(metrics_df_tun,columns=['max_iter','alpha','accuracy','AUC-ROC','AP'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_iter</th>\n",
       "      <th>alpha</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.631605</td>\n",
       "      <td>0.683375</td>\n",
       "      <td>0.177510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.719416</td>\n",
       "      <td>0.677819</td>\n",
       "      <td>0.178257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>0.666983</td>\n",
       "      <td>0.172305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.766023</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.160054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.769642</td>\n",
       "      <td>0.633799</td>\n",
       "      <td>0.157008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.781168</td>\n",
       "      <td>0.624681</td>\n",
       "      <td>0.155411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.786736</td>\n",
       "      <td>0.622881</td>\n",
       "      <td>0.154769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.806197</td>\n",
       "      <td>0.620745</td>\n",
       "      <td>0.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.898435</td>\n",
       "      <td>0.621742</td>\n",
       "      <td>0.154708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_iter     alpha  accuracy   AUC-ROC        AP\n",
       "0        25  0.000001  0.631605  0.683375  0.177510\n",
       "1       100  0.000050  0.719416  0.677819  0.178257\n",
       "2       250  0.000100  0.740047  0.666983  0.172305\n",
       "3       500  0.000500  0.766023  0.641739  0.160054\n",
       "4       750  0.001000  0.769642  0.633799  0.157008\n",
       "5      1000  0.005000  0.781168  0.624681  0.155411\n",
       "6      1250  0.010000  0.786736  0.622881  0.154769\n",
       "7      1500  0.100000  0.806197  0.620745  0.153900\n",
       "8      2000  0.200000  0.898435  0.621742  0.154708"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_tun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further tuning below...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=[25,100,250,500,750,1000,1250,1300,1500,2000]\n",
    "alpha=[0.000001,0.00005,0.00001,0.0001, 0.0005,0.001,0.005,0.01,0.1,0.2]\n",
    "#loss=['hinge','log','squared_loss']\n",
    "#penalty=['l1','l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 1e-06\n",
      "25 5e-05\n",
      "25 1e-05\n",
      "25 0.0001\n",
      "25 0.0005\n",
      "25 0.001\n",
      "25 0.005\n",
      "25 0.01\n",
      "25 0.1\n",
      "25 0.2\n",
      "100 1e-06\n",
      "100 5e-05\n",
      "100 1e-05\n",
      "100 0.0001\n",
      "100 0.0005\n",
      "100 0.001\n",
      "100 0.005\n",
      "100 0.01\n",
      "100 0.1\n",
      "100 0.2\n",
      "250 1e-06\n",
      "250 5e-05\n",
      "250 1e-05\n",
      "250 0.0001\n",
      "250 0.0005\n",
      "250 0.001\n",
      "250 0.005\n",
      "250 0.01\n",
      "250 0.1\n",
      "250 0.2\n",
      "500 1e-06\n",
      "500 5e-05\n",
      "500 1e-05\n",
      "500 0.0001\n",
      "500 0.0005\n",
      "500 0.001\n",
      "500 0.005\n",
      "500 0.01\n",
      "500 0.1\n",
      "500 0.2\n",
      "750 1e-06\n",
      "750 5e-05\n",
      "750 1e-05\n",
      "750 0.0001\n",
      "750 0.0005\n",
      "750 0.001\n",
      "750 0.005\n",
      "750 0.01\n",
      "750 0.1\n",
      "750 0.2\n",
      "1000 1e-06\n",
      "1000 5e-05\n",
      "1000 1e-05\n",
      "1000 0.0001\n",
      "1000 0.0005\n",
      "1000 0.001\n",
      "1000 0.005\n",
      "1000 0.01\n",
      "1000 0.1\n",
      "1000 0.2\n",
      "1250 1e-06\n",
      "1250 5e-05\n",
      "1250 1e-05\n",
      "1250 0.0001\n",
      "1250 0.0005\n",
      "1250 0.001\n",
      "1250 0.005\n",
      "1250 0.01\n",
      "1250 0.1\n",
      "1250 0.2\n",
      "1300 1e-06\n",
      "1300 5e-05\n",
      "1300 1e-05\n",
      "1300 0.0001\n",
      "1300 0.0005\n",
      "1300 0.001\n",
      "1300 0.005\n",
      "1300 0.01\n",
      "1300 0.1\n",
      "1300 0.2\n",
      "1500 1e-06\n",
      "1500 5e-05\n",
      "1500 1e-05\n",
      "1500 0.0001\n",
      "1500 0.0005\n",
      "1500 0.001\n",
      "1500 0.005\n",
      "1500 0.01\n",
      "1500 0.1\n",
      "1500 0.2\n",
      "2000 1e-06\n",
      "2000 5e-05\n",
      "2000 1e-05\n",
      "2000 0.0001\n",
      "2000 0.0005\n",
      "2000 0.001\n",
      "2000 0.005\n",
      "2000 0.01\n",
      "2000 0.1\n",
      "2000 0.2\n"
     ]
    }
   ],
   "source": [
    "tun_iter = []\n",
    "tun_alpha = []\n",
    "tun_acc = []\n",
    "tun_roc = []\n",
    "tun_ap = []\n",
    "\n",
    "for i in range(len(max_iter)):\n",
    "    for j in range(len(alpha)):\n",
    "        sgd_tun = SGDClassifier(loss='log',penalty='l2',max_iter=max_iter[i], alpha=alpha[j],fit_intercept=True)\n",
    "        sgd_tun.fit(samp_train,samp_targ)\n",
    "        predics_tun = sgd_tun.predict(test_vectors)\n",
    "        proba_tun = sgd_tun.predict_proba(test_vectors)\n",
    "    \n",
    "        tun_iter.append(max_iter[i])\n",
    "        tun_alpha.append(alpha[j])\n",
    "    \n",
    "        predics_prob_tun = []\n",
    "        print(max_iter[i],alpha[j])\n",
    "        for t in range(len(proba_tun)):\n",
    "            predics_prob_tun.append(proba_tun[t][1])\n",
    "    \n",
    "        tun_acc.append(sklearn.metrics.accuracy_score(test_targets, predics_tun, normalize=True))\n",
    "        tun_roc.append(sklearn.metrics.roc_auc_score(test_targets,predics_prob_tun))\n",
    "        tun_ap.append(sklearn.metrics.average_precision_score(test_targets,predics_prob_tun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics from further tuning (top results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metric_df = list(zip(tun_iter,tun_alpha,tun_acc,tun_roc,tun_ap))\n",
    "new_metric_df = pd.DataFrame(new_metric_df,columns=['max_iter','alpha','accuracy','AUC-ROC','AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_iter</th>\n",
       "      <th>alpha</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.661340</td>\n",
       "      <td>0.694041</td>\n",
       "      <td>0.188746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>250</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>0.693745</td>\n",
       "      <td>0.188357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.662119</td>\n",
       "      <td>0.693689</td>\n",
       "      <td>0.188043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.660672</td>\n",
       "      <td>0.693630</td>\n",
       "      <td>0.188491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.660588</td>\n",
       "      <td>0.693601</td>\n",
       "      <td>0.188275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_iter    alpha  accuracy   AUC-ROC        AP\n",
       "52      1000  0.00001  0.661340  0.694041  0.188746\n",
       "22       250  0.00001  0.664207  0.693745  0.188357\n",
       "72      1300  0.00001  0.662119  0.693689  0.188043\n",
       "12       100  0.00001  0.660672  0.693630  0.188491\n",
       "62      1250  0.00001  0.660588  0.693601  0.188275"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metric_df.sort_values(by='AUC-ROC', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters and metrics from tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tun = SGDClassifier(loss='log',penalty= 'l2', max_iter=1000 ,alpha=0.000010,fit_intercept= True)\n",
    "sgd_tun.fit(samp_train,samp_targ)\n",
    "new_predics = sgd_tun.predict(test_vectors)\n",
    "new_proba = sgd_tun.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_proba_ones = []\n",
    "for t in range(len(new_proba)):\n",
    "    new_proba_ones.append(new_proba[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters and metrics after tuning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.769670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.633853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.157045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   95\n",
       "max_iter  2000.000000\n",
       "alpha        0.001000\n",
       "accuracy     0.769670\n",
       "AUC-ROC      0.633853\n",
       "AP           0.157045"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tuning = pd.DataFrame(new_metric_df.iloc[52])\n",
    "print(\"Best hyperparameters and metrics after tuning:\")\n",
    "best_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on tuned model trained WITHOUT upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, loss='log')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_tun.fit(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_unsamp_predics = sgd_tun.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_prob = sgd_tun.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_probz_tun = []\n",
    "   \n",
    "for i in range(len(predics_prob)):\n",
    "    predics_probz_tun.append(predics_prob[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tun_unsamp = sklearn.metrics.accuracy_score(test_targets, new_predics, normalize=True)\n",
    "roc_tun_unsamp = sklearn.metrics.roc_auc_score(test_targets,predics_probz_tun)\n",
    "ap_tun_unsamp = sklearn.metrics.average_precision_score(test_targets,predics_probz_tun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tun_unsamp = [acc_tun_unsamp,roc_tun_unsamp,ap_tun_unsamp]\n",
    "metric_tun_unsamp = pd.DataFrame(metric_tun_unsamp, index=['accuracy','AUC-ROC','AP'],columns=['Tuning_not_sampled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_met = [0.769670,0.633853,0.157045] #copied values from best_tuning table \n",
    "best_tuning_metric = pd.DataFrame(tuning_met,index=['accuracy','AUC-ROC','AP'],columns=['Tuning_sampled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "      <th>Upsampled_no_tuning</th>\n",
       "      <th>Tuning_not_sampled</th>\n",
       "      <th>Tuning_sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898240</td>\n",
       "      <td>0.662648</td>\n",
       "      <td>0.665405</td>\n",
       "      <td>0.769670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714675</td>\n",
       "      <td>0.693540</td>\n",
       "      <td>0.715131</td>\n",
       "      <td>0.633853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.207655</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.208533</td>\n",
       "      <td>0.157045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics  Upsampled_no_tuning  Tuning_not_sampled  \\\n",
       "accuracy          0.898240             0.662648            0.665405   \n",
       "AUC-ROC           0.714675             0.693540            0.715131   \n",
       "AP                0.207655             0.188034            0.208533   \n",
       "\n",
       "          Tuning_sampled  \n",
       "accuracy        0.769670  \n",
       "AUC-ROC         0.633853  \n",
       "AP              0.157045  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics_raw,metric_up,metric_tun_unsamp,best_tuning_metric],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO if time ..... (must re-run notebook):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsample - Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=5)\n",
    "train_ros, targ_ros = ros.fit_resample(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tun.fit(train_ros,targ_ros) \n",
    "ros_predics = sgd_tun.predict(test_vectors) \n",
    "y_scor = sgd_tun.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scor_ones = []\n",
    "for i in range(len(y_scor)):\n",
    "        y_scor_ones.append(y_scor[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_tun_acc = sklearn.metrics.accuracy_score(test_targets, ros_predics, normalize=True)\n",
    "ros_tun_roc = sklearn.metrics.roc_auc_score(test_targets,y_scor_ones)\n",
    "ros_tun_ap = sklearn.metrics.average_precision_score(test_targets,y_scor_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample - Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=5) \n",
    "train_rus, targ_rus = rus.fit_resample(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tun.fit(train_rus,targ_rus) \n",
    "rus_predics = sgd_tun.predict(test_vectors) \n",
    "y_scor = sgd_tun.predict_proba(test_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scor_ones = []\n",
    "for i in range(len(y_scor)):\n",
    "        y_scor_ones.append(y_scor[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_tun_acc = sklearn.metrics.accuracy_score(test_targets, rus_predics, normalize=True)\n",
    "rus_tun_roc = sklearn.metrics.roc_auc_score(test_targets,y_scor_ones)\n",
    "rus_tun_ap = sklearn.metrics.average_precision_score(test_targets,y_scor_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 'dev' data to training + redo preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out a small portion of 'dev' to evaluate model with added data\n",
    "from sklearn.model_selection import train_test_split\n",
    "dev_train, dev_test = train_test_split(dev, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train2 = pd.raw_train.drop('cleaned_review')\n",
    "raw_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train = pd.concat([raw_train2,dev_train],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz=[]\n",
    "for i in range(len(comb_train)):\n",
    "    tokenz.append(word_tokenize(comb_train['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz_filt = tokenz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokenz_filt[w][i].lower() in stop_words:\n",
    "            tokenz_filt[w].remove(tokenz_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokenz_filt[w][i] in punct:\n",
    "            tokenz_filt[w].remove(tokenz_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        tokenz_filt[w][i] = (ps.stem(tokenz_filt[w][i]))\n",
    "        del count[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_targets=comb_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train2['cleaned_review'] = tokenz_filt\n",
    "df2=pd.DataFrame(raw_train2['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)): \n",
    "    df2['cleaned_review'][i]=\" \".join(df2['cleaned_review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train_vectors = vectorizer.fit_transform(df2['cleaned_review'])\n",
    "comb_test_vectors = vectorizer.transform(dev_test['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions / Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier \n",
    "sgd_tun.fit(comb_train_vectors,comb_targets) \n",
    "comb_predics = sgd_tun.predict(comb_test_vectors) \n",
    "comb_predics_prob = sgd_tun.predict_proba(comb_test_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate probability scores for positive class\n",
    "y_ones = []\n",
    "for i in range(len(comb_predics_prob)):\n",
    "        y_ones.append(comb_predics_prob[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = dev_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_acc = sklearn.metrics.accuracy_score(test_targets, comb_predics, normalize=True)\n",
    "comb_roc = sklearn.metrics.roc_auc_score(test_targets,y_ones)\n",
    "comb_ap = sklearn.metrics.average_precision_score(test_targets,y_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add remaining portion (20%) of 'dev' to training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must repeat previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_comb = pd.concat([comb_train,dev_test],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
