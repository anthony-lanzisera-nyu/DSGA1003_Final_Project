{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nylaennels/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nylaennels/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('/Users/nylaennels/Desktop/train.csv')\n",
    "dev = pd.read_csv('/Users/nylaennels/Desktop/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id  user_id  prod_id  rating  label        date  \\\n",
       "0      0      923        0     3.0      1  2014-12-08   \n",
       "1      1      924        0     3.0      1  2013-05-16   \n",
       "2      2      925        0     4.0      1  2013-07-01   \n",
       "3      3      926        0     4.0      1  2011-07-28   \n",
       "4      4      927        0     4.0      1  2010-11-01   \n",
       "\n",
       "                                              review  \n",
       "0  The food at snack is a selection of popular Gr...  \n",
       "1  This little place in Soho is wonderful. I had ...  \n",
       "2  ordered lunch for 15 from Snack last Friday.  ...  \n",
       "3  This is a beautiful quaint little restaurant o...  \n",
       "4  Snack is great place for a  casual sit down lu...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "for i in range(len(raw_train)):\n",
    "    tokens.append(word_tokenize(raw_train['review'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "tokens_filt = tokens.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokens_filt[w][i].lower() in stop_words:\n",
    "            tokens_filt[w].remove(tokens_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = ['?','.','!','(',')',',','...',';','''''','\"\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokens_filt[w][i] in punct:\n",
    "            tokens_filt[w].remove(tokens_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(len(tokens_filt)): #w = review index\n",
    "    count=list(range(len(tokens_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        tokens_filt[w][i] = (ps.stem(tokens_filt[w][i]))\n",
    "        del count[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of unlinked words (for vectorizer)\n",
    "#unlinked_train = []\n",
    "#for w in range(len(tokens_filt)): #w = review index\n",
    "#    count=list(range(len(tokens_filt[w])))\n",
    "#    for i in count: #i = word index\n",
    "#        unlinked_train.append(tokens_filt[w][i])\n",
    "#        del count[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=raw_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train['cleaned_review'] = tokens_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(raw_train['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covnert column from list type to str type\n",
    "for i in range(len(df)): \n",
    "    df['cleaned_review'][i]=\" \".join(df['cleaned_review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tf-idf vectorizer\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(df['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dta = dev['review'] #use dev file as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = vectorizer.transform(test_dta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize baseline model & make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, loss='log', max_iter=50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a classifier \n",
    "sgd = SGDClassifier(loss='log',penalty= 'l2', max_iter= 50,\n",
    "                                             alpha= 0.00001,fit_intercept= True)\n",
    "# Fit the classifier \n",
    "sgd.fit(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics = sgd.predict(test_vectors)\n",
    "predics_prob = sgd.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = dev['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - BEFORE UPSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the prediction probabilites of the postive class\n",
    "predics_prob_ones = []\n",
    "for i in range(len(predics_prob)):\n",
    "    predics_prob_ones.append(predics_prob[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_prob_ones = np.array(predics_prob_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, AUC-ROC, AP\n",
    "acc_raw = sklearn.metrics.accuracy_score(test_targets, predics, normalize=True)\n",
    "roc_raw = sklearn.metrics.roc_auc_score(test_targets,predics_prob_ones)\n",
    "ap_raw = sklearn.metrics.average_precision_score(test_targets,predics_prob_ones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.208361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics\n",
       "accuracy          0.898185\n",
       "AUC-ROC           0.714909\n",
       "AP                0.208361"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_raw = [acc_raw,roc_raw,ap_raw]\n",
    "metrics_raw = pd.DataFrame(metrics_raw, index=['accuracy','AUC-ROC','AP'], columns=['Baseline_Metrics'])\n",
    "metrics_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-sample - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = raw_train.drop(columns=['ex_id','user_id','prod_id','rating','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamp = SMOTE(random_state=5)\n",
    "samp_train,samp_targ = upsamp.fit_resample(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using up-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samp_train_vectors = vectorizer.transform(samp_df['cleaned_review'])\n",
    "sgd.fit(samp_train,samp_targ)\n",
    "samp_predics = sgd.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using predict_proba for probability scores for metrics\n",
    "y_score = sgd.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - AFTER SMOTE UPSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate probablity predictions for the positive class\n",
    "predics_prob_1 = []\n",
    "for i in range(len(y_score)):\n",
    "    predics_prob_1.append(y_score[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_SMOTE = sklearn.metrics.accuracy_score(test_targets, samp_predics, normalize=True)\n",
    "roc_SMOTE = sklearn.metrics.roc_auc_score(test_targets,predics_prob_1)\n",
    "ap_SMOTE = sklearn.metrics.average_precision_score(test_targets,predics_prob_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_upsamp = [acc_SMOTE,roc_SMOTE,ap_SMOTE]\n",
    "metric_up = pd.DataFrame(metrics_upsamp, columns=['Upsampled_no_tuning'], index=['accuracy','AUC-ROC','AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "      <th>Upsampled_no_tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898185</td>\n",
       "      <td>0.669386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714909</td>\n",
       "      <td>0.693450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.208361</td>\n",
       "      <td>0.188060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics  Upsampled_no_tuning\n",
       "accuracy          0.898185             0.669386\n",
       "AUC-ROC           0.714909             0.693450\n",
       "AP                0.208361             0.188060"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics_raw,metric_up],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - using SMOTE upsampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_grid = [25,100,250,500,750,1000,1250,1500,2000]\n",
    "alpha_grid = [0.000001,0.00005,0.0001,0.0005,0.001,0.005,0.01,0.1,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_iter = []\n",
    "tun_alpha = []\n",
    "tun_acc = []\n",
    "tun_roc = []\n",
    "tun_ap = []\n",
    "\n",
    "for i in range(0,9):\n",
    "    sgd_tun = SGDClassifier(loss='log',penalty='l2',max_iter=max_iter_grid[i], alpha=alpha_grid[i],fit_intercept=True)\n",
    "    sgd_tun.fit(samp_train,samp_targ)\n",
    "    predics_tun = sgd_tun.predict(test_vectors)\n",
    "    proba_tun = sgd_tun.predict_proba(test_vectors)\n",
    "    \n",
    "    tun_iter.append(max_iter_grid[i])\n",
    "    tun_alpha.append(alpha_grid[i])\n",
    "    \n",
    "    predics_prob_tun = []\n",
    "   \n",
    "    for i in range(len(proba_tun)):\n",
    "        predics_prob_tun.append(proba_tun[i][1])\n",
    "    \n",
    "    tun_acc.append(sklearn.metrics.accuracy_score(test_targets, predics_tun, normalize=True))\n",
    "    tun_roc.append(sklearn.metrics.roc_auc_score(test_targets,predics_prob_tun))\n",
    "    tun_ap.append(sklearn.metrics.average_precision_score(test_targets,predics_prob_tun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics from first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_tun = list(zip(tun_iter,tun_alpha,tun_acc,tun_roc,tun_ap))\n",
    "metrics_df_tun = pd.DataFrame(metrics_df_tun,columns=['max_iter','alpha','accuracy','AUC-ROC','AP'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_iter</th>\n",
       "      <th>alpha</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.633916</td>\n",
       "      <td>0.683958</td>\n",
       "      <td>0.178470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.717133</td>\n",
       "      <td>0.678036</td>\n",
       "      <td>0.178543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.739100</td>\n",
       "      <td>0.667096</td>\n",
       "      <td>0.172355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.765521</td>\n",
       "      <td>0.641784</td>\n",
       "      <td>0.160083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.769893</td>\n",
       "      <td>0.633815</td>\n",
       "      <td>0.157024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.781920</td>\n",
       "      <td>0.624712</td>\n",
       "      <td>0.155435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.797121</td>\n",
       "      <td>0.623296</td>\n",
       "      <td>0.155077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.856145</td>\n",
       "      <td>0.621044</td>\n",
       "      <td>0.154104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.825547</td>\n",
       "      <td>0.620626</td>\n",
       "      <td>0.153859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_iter     alpha  accuracy   AUC-ROC        AP\n",
       "0        25  0.000001  0.633916  0.683958  0.178470\n",
       "1       100  0.000050  0.717133  0.678036  0.178543\n",
       "2       250  0.000100  0.739100  0.667096  0.172355\n",
       "3       500  0.000500  0.765521  0.641784  0.160083\n",
       "4       750  0.001000  0.769893  0.633815  0.157024\n",
       "5      1000  0.005000  0.781920  0.624712  0.155435\n",
       "6      1250  0.010000  0.797121  0.623296  0.155077\n",
       "7      1500  0.100000  0.856145  0.621044  0.154104\n",
       "8      2000  0.200000  0.825547  0.620626  0.153859"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_tun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further tuning below...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=[25,100,250,500,750,1000,1250,1300,1500,2000]\n",
    "alpha=[0.000001,0.00005,0.00001,0.0001, 0.0005,0.001,0.005,0.01,0.1,0.2]\n",
    "#loss=['hinge','log','squared_loss']\n",
    "#penalty=['l1','l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 1e-06\n",
      "25 5e-05\n",
      "25 1e-05\n",
      "25 0.0001\n",
      "25 0.0005\n",
      "25 0.001\n",
      "25 0.005\n",
      "25 0.01\n",
      "25 0.1\n",
      "25 0.2\n",
      "100 1e-06\n",
      "100 5e-05\n",
      "100 1e-05\n",
      "100 0.0001\n",
      "100 0.0005\n",
      "100 0.001\n",
      "100 0.005\n",
      "100 0.01\n",
      "100 0.1\n",
      "100 0.2\n",
      "250 1e-06\n",
      "250 5e-05\n",
      "250 1e-05\n",
      "250 0.0001\n",
      "250 0.0005\n",
      "250 0.001\n",
      "250 0.005\n",
      "250 0.01\n",
      "250 0.1\n",
      "250 0.2\n",
      "500 1e-06\n",
      "500 5e-05\n",
      "500 1e-05\n",
      "500 0.0001\n",
      "500 0.0005\n",
      "500 0.001\n",
      "500 0.005\n",
      "500 0.01\n",
      "500 0.1\n",
      "500 0.2\n",
      "750 1e-06\n",
      "750 5e-05\n",
      "750 1e-05\n",
      "750 0.0001\n",
      "750 0.0005\n",
      "750 0.001\n",
      "750 0.005\n",
      "750 0.01\n",
      "750 0.1\n",
      "750 0.2\n",
      "1000 1e-06\n",
      "1000 5e-05\n",
      "1000 1e-05\n",
      "1000 0.0001\n",
      "1000 0.0005\n",
      "1000 0.001\n",
      "1000 0.005\n",
      "1000 0.01\n",
      "1000 0.1\n",
      "1000 0.2\n",
      "1250 1e-06\n",
      "1250 5e-05\n",
      "1250 1e-05\n",
      "1250 0.0001\n",
      "1250 0.0005\n",
      "1250 0.001\n",
      "1250 0.005\n",
      "1250 0.01\n",
      "1250 0.1\n",
      "1250 0.2\n",
      "1300 1e-06\n",
      "1300 5e-05\n",
      "1300 1e-05\n",
      "1300 0.0001\n",
      "1300 0.0005\n",
      "1300 0.001\n",
      "1300 0.005\n",
      "1300 0.01\n",
      "1300 0.1\n",
      "1300 0.2\n",
      "1500 1e-06\n",
      "1500 5e-05\n",
      "1500 1e-05\n",
      "1500 0.0001\n",
      "1500 0.0005\n",
      "1500 0.001\n",
      "1500 0.005\n",
      "1500 0.01\n",
      "1500 0.1\n",
      "1500 0.2\n",
      "2000 1e-06\n",
      "2000 5e-05\n",
      "2000 1e-05\n",
      "2000 0.0001\n",
      "2000 0.0005\n",
      "2000 0.001\n",
      "2000 0.005\n",
      "2000 0.01\n",
      "2000 0.1\n",
      "2000 0.2\n"
     ]
    }
   ],
   "source": [
    "tun_iter = []\n",
    "tun_alpha = []\n",
    "tun_acc = []\n",
    "tun_roc = []\n",
    "tun_ap = []\n",
    "\n",
    "for i in range(len(max_iter)):\n",
    "    for j in range(len(alpha)):\n",
    "        sgd_tun = SGDClassifier(loss='log',penalty='l2',max_iter=max_iter[i], alpha=alpha[j],fit_intercept=True)\n",
    "        sgd_tun.fit(samp_train,samp_targ)\n",
    "        predics_tun = sgd_tun.predict(test_vectors)\n",
    "        proba_tun = sgd_tun.predict_proba(test_vectors)\n",
    "    \n",
    "        tun_iter.append(max_iter[i])\n",
    "        tun_alpha.append(alpha[j])\n",
    "    \n",
    "        predics_prob_tun = []\n",
    "        print(max_iter[i],alpha[j])\n",
    "        for t in range(len(proba_tun)):\n",
    "            predics_prob_tun.append(proba_tun[t][1])\n",
    "    \n",
    "        tun_acc.append(sklearn.metrics.accuracy_score(test_targets, predics_tun, normalize=True))\n",
    "        tun_roc.append(sklearn.metrics.roc_auc_score(test_targets,predics_prob_tun))\n",
    "        tun_ap.append(sklearn.metrics.average_precision_score(test_targets,predics_prob_tun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics from further tuning (top results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metric_df = list(zip(tun_iter,tun_alpha,tun_acc,tun_roc,tun_ap))\n",
    "new_metric_df = pd.DataFrame(new_metric_df,columns=['max_iter','alpha','accuracy','AUC-ROC','AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_iter</th>\n",
       "      <th>alpha</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.662982</td>\n",
       "      <td>0.693747</td>\n",
       "      <td>0.188325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.661869</td>\n",
       "      <td>0.693692</td>\n",
       "      <td>0.187992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.663539</td>\n",
       "      <td>0.693656</td>\n",
       "      <td>0.188214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.664681</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.188103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>0.693593</td>\n",
       "      <td>0.188132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_iter    alpha  accuracy   AUC-ROC        AP\n",
       "62      1250  0.00001  0.662982  0.693747  0.188325\n",
       "72      1300  0.00001  0.661869  0.693692  0.187992\n",
       "2         25  0.00001  0.663539  0.693656  0.188214\n",
       "92      2000  0.00001  0.664681  0.693654  0.188103\n",
       "12       100  0.00001  0.657999  0.693593  0.188132"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metric_df.sort_values(by='AUC-ROC', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters and metrics from tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tun = SGDClassifier(loss='log',penalty= 'l2', max_iter=1000 ,alpha=0.000010,fit_intercept= True)\n",
    "sgd_tun.fit(samp_train,samp_targ)\n",
    "new_predics = sgd_tun.predict(test_vectors)\n",
    "new_proba = sgd_tun.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_proba_ones = []\n",
    "for t in range(len(new_proba)):\n",
    "    new_proba_ones.append(new_proba[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters and metrics after tuning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.641545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.683979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.177926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "max_iter  25.000000\n",
       "alpha      0.000001\n",
       "accuracy   0.641545\n",
       "AUC-ROC    0.683979\n",
       "AP         0.177926"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tuning = pd.DataFrame(new_metric_df.iloc[0])\n",
    "print(\"Best hyperparameters and metrics after tuning:\")\n",
    "best_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on tuned model trained WITHOUT upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, loss='log')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_tun.fit(train_vectors,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_unsamp_predics = sgd_tun.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_prob = sgd_tun.predict_proba(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics_probz_tun = []\n",
    "   \n",
    "for i in range(len(predics_prob)):\n",
    "    predics_probz_tun.append(predics_prob[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tun_unsamp = sklearn.metrics.accuracy_score(test_targets, new_predics, normalize=True)\n",
    "roc_tun_unsamp = sklearn.metrics.roc_auc_score(test_targets,predics_probz_tun)\n",
    "ap_tun_unsamp = sklearn.metrics.average_precision_score(test_targets,predics_probz_tun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_tun_unsamp = [acc_tun_unsamp,roc_tun_unsamp,ap_tun_unsamp]\n",
    "metric_tun_unsamp = pd.DataFrame(metric_tun_unsamp, index=['accuracy','AUC-ROC','AP'],columns=['Tuning_not_sampled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_met = [0.769670,0.633853,0.157045] #copied values from best_tuning table \n",
    "best_tuning_metric = pd.DataFrame(tuning_met,index=['accuracy','AUC-ROC','AP'],columns=['Tuning_sampled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline_Metrics</th>\n",
       "      <th>Upsampled_no_tuning</th>\n",
       "      <th>Tuning_not_sampled</th>\n",
       "      <th>Tuning_sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898185</td>\n",
       "      <td>0.669386</td>\n",
       "      <td>0.654714</td>\n",
       "      <td>0.769670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-ROC</th>\n",
       "      <td>0.714909</td>\n",
       "      <td>0.693450</td>\n",
       "      <td>0.714954</td>\n",
       "      <td>0.633853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.208361</td>\n",
       "      <td>0.188060</td>\n",
       "      <td>0.208065</td>\n",
       "      <td>0.157045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline_Metrics  Upsampled_no_tuning  Tuning_not_sampled  \\\n",
       "accuracy          0.898185             0.669386            0.654714   \n",
       "AUC-ROC           0.714909             0.693450            0.714954   \n",
       "AP                0.208361             0.188060            0.208065   \n",
       "\n",
       "          Tuning_sampled  \n",
       "accuracy        0.769670  \n",
       "AUC-ROC         0.633853  \n",
       "AP              0.157045  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics_raw,metric_up,metric_tun_unsamp,best_tuning_metric],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Gradescope Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATE BEST MODEL ON TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('/Users/nylaennels/Desktop/test_no_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>929</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-25</td>\n",
       "      <td>Let me start with a shout-out to everyone who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>Stopped in for lunch today and couldn't believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>937</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-15</td>\n",
       "      <td>Tiny little place, but very good food. Pastits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>945</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>Food was delicious and service was great. Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>Awesome hole in the wall place to grab a quick...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id  user_id  prod_id  rating  label        date  \\\n",
       "0      6      929        0     4.0    NaN  2009-08-25   \n",
       "1      9      932        0     5.0    NaN  2014-05-09   \n",
       "2     14      937        0     4.0    NaN  2014-10-15   \n",
       "3     22      945        0     5.0    NaN  2014-04-10   \n",
       "4     23      946        0     5.0    NaN  2014-03-29   \n",
       "\n",
       "                                              review  \n",
       "0  Let me start with a shout-out to everyone who ...  \n",
       "1  Stopped in for lunch today and couldn't believ...  \n",
       "2  Tiny little place, but very good food. Pastits...  \n",
       "3  Food was delicious and service was great. Good...  \n",
       "4  Awesome hole in the wall place to grab a quick...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Let me start with a shout-out to everyone who ...\n",
       "1    Stopped in for lunch today and couldn't believ...\n",
       "2    Tiny little place, but very good food. Pastits...\n",
       "3    Food was delicious and service was great. Good...\n",
       "4    Awesome hole in the wall place to grab a quick...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews = test_set['review']\n",
    "test_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize test set + predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_vectors = vectorizer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, loss='log')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_tun.fit(train_vectors,targets) #best model according to ROC-AUC and AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = sgd_tun.predict(final_test_vectors)\n",
    "final_proba = sgd_tun.predict_proba(final_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yscore = []\n",
    "for t in range(len(final_proba)):\n",
    "    final_yscore.append(final_proba[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yscore_df = pd.DataFrame(final_yscore,columns=['probability_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_yscore_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_yscore_df.to_csv('/Users/nylaennels/Desktop/predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Gradescope Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 'dev' data to training data $\\rightarrow$ re-train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train2 = pd.DataFrame(raw_train['review'])\n",
    "dev_int = pd.DataFrame(dev['review'])\n",
    "final_train = pd.concat([raw_train2,dev_int],axis=0, ignore_index=True) #stacks dfs in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train2_targets = raw_train['label']\n",
    "dev_int_targets = dev['label']\n",
    "final_train_targets = pd.concat([raw_train2_targets,dev_int_targets],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(final_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(final_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-do text preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz=[]\n",
    "for i in range(len(final_train)):\n",
    "    tokenz.append(word_tokenize(final_train['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz_filt = tokenz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokenz_filt[w][i].lower() in stop_words:\n",
    "            tokenz_filt[w].remove(tokenz_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        if tokenz_filt[w][i] in punct:\n",
    "            tokenz_filt[w].remove(tokenz_filt[w][i])\n",
    "            del count[-1]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "for w in range(len(tokenz_filt)): #w = review index\n",
    "    count=list(range(len(tokenz_filt[w])))\n",
    "    for i in count: #i = word index\n",
    "        tokenz_filt[w][i] = (ps.stem(tokenz_filt[w][i]))\n",
    "        del count[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-vectorize new training data and corresponding targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train['cleaned_review'] = tokenz_filt\n",
    "df2=pd.DataFrame(final_train['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)): \n",
    "    df2['cleaned_review'][i]=\" \".join(df2['cleaned_review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train_vectors = vectorizer.fit_transform(df2['cleaned_review']) #run above 'transform' test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#VIEW\n",
    "#results = pd.DataFrame(comb_train_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_tun.fit(comb_train_vectors,final_train_targets) \n",
    "comb_predics = sgd_tun.predict(final_test_vectors) \n",
    "comb_predics_proba = sgd_tun.predict_proba(final_test_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate probability scores for positive class\n",
    "final_y_ones = []\n",
    "for i in range(len(comb_predics_proba)):\n",
    "        final_y_ones.append(comb_predics_proba[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export final predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probability_score\n",
       "0           0.048973\n",
       "1           0.140689\n",
       "2           0.194288\n",
       "3           0.081263\n",
       "4           0.077449"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_yscore_ = pd.DataFrame(final_y_ones,columns=['probability_score'])\n",
    "final_yscore_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_yscore_.to_csv('/Users/nylaennels/Desktop/predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
