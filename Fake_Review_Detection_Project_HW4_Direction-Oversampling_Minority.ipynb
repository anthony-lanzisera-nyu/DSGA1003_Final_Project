{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1: fake review detection\n",
    "Data\n",
    "This dataset includes reviews for restaurants located in New York City. Reviews include product and user id, timestamp, ratings, and a plaintext review. Yelp has a filtering algorithm in place that identifies fake/suspicious reviews and separates them into a filtered list. This Yelp dataset contains both recommended and filtered reviews. We consider them as genuine and fake, respectively. Your goal is to predict whether a review is fake or not, i.e. a binary classification task. The positive classes (+1) are fake reviews and the negative classes are genuine reviews (0). Note that the classes are imbalanced, with around 10% fake reviews. \n",
    "\n",
    "Evaluation\n",
    "Your model should output a score for each example; higher score indicates the example is more likely to be fake.\n",
    "We will evaluate the results using auROC and AP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in Dataset from Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "train_df_pre = pd.read_csv(path+\"/train.csv\")\n",
    "validation_df_pre = pd.read_csv(path+\"/dev.csv\")\n",
    "#HW4 has 1, -1 as labels, so convert 0 to -1\n",
    "train_df_pre['label'] = train_df_pre['label'].replace(to_replace=0,value=-1)\n",
    "validation_df_pre['label'] = validation_df_pre['label'].replace(to_replace=0,value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1: 225055, 1: 25819})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(train_df_pre['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>934</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>all around good place, cozy, I came in and did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>For lunch, my friend and I had: -Lamb sandwich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>Some good Big Greek cooking!! Came to City on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>So... as you may notice from some of my other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>I don't understand the whole \"You can't order ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id  user_id  prod_id  rating  label        date  \\\n",
       "0     11      934        0     5.0      1  2014-01-20   \n",
       "1     17      940        0     4.0     -1  2014-09-16   \n",
       "2     20      943        0     5.0     -1  2014-05-24   \n",
       "3     30      953        0     4.0     -1  2013-10-17   \n",
       "4     43      966        0     3.0     -1  2012-12-19   \n",
       "\n",
       "                                              review  \n",
       "0  all around good place, cozy, I came in and did...  \n",
       "1  For lunch, my friend and I had: -Lamb sandwich...  \n",
       "2  Some good Big Greek cooking!! Came to City on ...  \n",
       "3  So... as you may notice from some of my other ...  \n",
       "4  I don't understand the whole \"You can't order ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Should we normalize case?  e.g., does HELLO mean Hello mean hello?\n",
    "- Should we remove stop words?\n",
    "- Should we remove punctuation, special symbols?\n",
    "- Should we lemmatise?  \"There is currently no lemmatiser with a very high accuracy rate:\n",
    "e.g., caresses -> caress ponies -> poni etc.\n",
    "- Less common are error correction, converting words to parts of speech, mapping synonyms to one.  In nltk library.\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = stem.SnowballStemmer('english')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def sample_normalizer(msg):\n",
    "    #converting messages to lowercase\n",
    "    msg = msg.lower()\n",
    "    #removing stopwords\n",
    "    msg = [word for word in msg.split() if word not in stopwords]\n",
    "    #using a stemmer\n",
    "    msg = \" \".join([stemmer.stem(word) for word in msg])\n",
    "    return msg\n",
    "\n",
    "data['text'] = data['text'].apply(review_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training, remove special symbols, and remake list(review), label combos.\n",
    "train_df = []\n",
    "symbols = '${}()[].,:;+-*/&|<>=~\" '\n",
    "for review, label in dict(zip(train_df_pre['review'],train_df_pre['label'])).items():\n",
    "    rvw = review.split(' ')\n",
    "    words = map(lambda Element: Element.translate(str.maketrans(\"\", \"\", symbols)).strip(), rvw)\n",
    "    words = filter(None, words)\n",
    "    r = list(words)\n",
    "    r.append(str(label))\n",
    "    train_df.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commented out since the below takes a while (2 minutes)\n",
    "#train_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = []\n",
    "symbols = '${}()[].,:;+-*/&|<>=~\" '\n",
    "for review, label in dict(zip(validation_df_pre['review'],validation_df_pre['label'])).items():\n",
    "    rvw = review.split(' ')\n",
    "    words = map(lambda Element: Element.translate(str.maketrans(\"\", \"\", symbols)).strip(), rvw)\n",
    "    words = filter(None, words)\n",
    "    r = list(words)\n",
    "    r.append(str(label))\n",
    "    validation_df.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commented out since the below takes a while (2 minutes)\n",
    "#validation_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Takes in a dataset. \n",
    "def BOW(dataset):\n",
    "    BOW_representation = {}\n",
    "    for i, review in enumerate(dataset):\n",
    "        count_this = review[:-1]\n",
    "        BOW_representation[i] = Counter(count_this)# For review i, count each word\n",
    "    return BOW_representation\n",
    "\n",
    "#One can slice and take one or many examples of a dataset, as the commented \n",
    "#out print() shows immediately below.\n",
    "#print(BOW(train_df[2:3])) #convert example 2 to BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: Counter({'lunch': 2, 'the': 2, 'ordered': 1, 'for': 1, '15': 1, 'from': 1, 'Snack': 1, 'last': 1, 'Friday': 1, 'On': 1, 'time': 1, 'nothing': 1, 'missing': 1, 'and': 1, 'food': 1, 'was': 1, 'great': 1, 'I': 1, 'have': 1, 'added': 1, 'it': 1, 'to': 1, 'regular': 1, 'company': 1, 'list': 1, 'as': 1, 'everyone': 1, 'enjoyed': 1, 'their': 1, 'meal': 1})}\n"
     ]
    }
   ],
   "source": [
    "print(BOW(train_df[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for k, v in BOW(train_df[2:3]).items():\n",
    "    for a,b in v.items():\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BOW = BOW(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'is': 3, 'The': 2, 'Greek': 2, 'the': 2, 'food': 1, 'at': 1, 'snack': 1, 'a': 1, 'selection': 1, 'of': 1, 'popular': 1, 'dishes': 1, 'appetizer': 1, 'tray': 1, 'good': 1, 'as': 1, 'salad': 1, 'We': 1, 'were': 1, 'underwhelmed': 1, 'with': 1, 'main': 1, 'courses': 1, 'There': 1, 'are': 1, '45': 1, 'tables': 1, 'here': 1, 'so': 1, \"it's\": 1, 'sometimes': 1, 'hard': 1, 'to': 1, 'get': 1, 'seated': 1})\n"
     ]
    }
   ],
   "source": [
    "print(X_BOW[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See my 5/15/2020 6:52 iPhone photo for how this looks\n",
    "X_BOW = []\n",
    "\n",
    "for k, v in BOW(train_df).items():\n",
    "    temp = []\n",
    "    for a,b in v.items():\n",
    "        temp.append(b)\n",
    "    X_BOW.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 4, 1, 1, 1, 3, 1, 7, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 2, 5, 4, 3, 1, 2, 7, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_BOW[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BOW = np.asarray(X_BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(min([len(u) for u in X_BOW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad to 659 each row\n",
    "X_BOW_post = [np.pad(row, pad_width=659, mode='constant', constant_values=0) for row in X_BOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "ovr = SMOTE(random_state = 42)\n",
    "X, y \\\n",
    "= ovr.fit_resample(X_BOW, train_df[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotProduct(d1, d2):\n",
    "    \"\"\"\n",
    "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
    "    @param dict d2: same as d1\n",
    "    @return float: the dot product between d1 and d2\n",
    "    \"\"\"\n",
    "    if len(d1) < len(d2):\n",
    "        return dotProduct(d2, d1)\n",
    "    else:\n",
    "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n",
    "\n",
    "def increment(d1, scale, d2):\n",
    "    \"\"\"\n",
    "    Implements d1 += scale * d2 for sparse vectors.\n",
    "    @param dict d1: the feature vector which is mutated.\n",
    "    @param float scale\n",
    "    @param dict d2: a feature vector.\n",
    "\n",
    "    NOTE: This function does not return anything, but rather\n",
    "    increments d1 in place. We do this because it is much faster to\n",
    "    change elements of d1 in place than to build a new dictionary and\n",
    "    return it.\n",
    "    \"\"\"\n",
    "    for f, v in d2.items():\n",
    "        d1[f] = d1.get(f, 0) + v * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_fast(review_list, max_epoch, lam):\n",
    "    W = {}\n",
    "    epoch = 0\n",
    "    t = 1\n",
    "    s = 1\n",
    "    x = BOW(review_list)\n",
    "    y = []\n",
    "    for review in review_list:\n",
    "        y.append(int(review[-1]))\n",
    "    #Loop\n",
    "    # Use the util.increment and util.dotProduct functions in update\n",
    "    #We use the results of problem 2 here in increment()\n",
    "    while epoch < max_epoch:\n",
    "        for j in range(len(x)):\n",
    "            t += 1\n",
    "            eta_t = 1/(t*lam)\n",
    "            s -= eta_t*lam*s\n",
    "            if y[j]*dotProduct(W,x[j])*s < 1:\n",
    "                increment(W,(eta_t*y[j])/s,x[j])        \n",
    "        epoch += 1\n",
    "    W.update((x,s*y) for x,y in W.items()) #Let's update in place.\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pegasos_fast = pegasos_fast(train_df, max_epoch = 3, lam = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_percent(review_list, weight):\n",
    "    x = BOW(review_list)\n",
    "    y = []\n",
    "    for review in review_list:\n",
    "        y.append(int(review[-1]))############4/20#####y.append(review[-1])\n",
    "        \n",
    "    error = 0\n",
    "    for i in range(len(x)):\n",
    "        if dotProduct(weight, x[i]) < 0:\n",
    "            pred = -1\n",
    "        else:\n",
    "            pred = 1\n",
    "        if y[i] != pred:\n",
    "            error += 1\n",
    "    return error/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_list = [0.000000001, 0.00000001, 0.0000001, 0.000001,0.00001, 0.0001, 0.001, 0.01, 0.1, 1,10, 100]\n",
    "loss_list = []\n",
    "for regularizer in lam_list:\n",
    "    weight = pegasos_fast(train_df,max_epoch=10, lam = regularizer)\n",
    "    loss = accuracy_percent(validation_df,weight)\n",
    "    loss_list.append(loss)\n",
    "print('Table of each Lambda and its Loss')\n",
    "for lam, loss in zip(lam_list, loss_list):\n",
    "    print(lam, loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "def evaluate_model(review_list, weight, evaluation_metric):\n",
    "    \n",
    "    x = BOW(review_list)\n",
    "    \n",
    "    y_true_pre = []\n",
    "    for review in review_list:\n",
    "        y_true_pre.append(int(review[-1]))\n",
    "    \n",
    "    y_scores_pre = [] #the model predictions\n",
    "    for i in range(len(x)):\n",
    "        if dotProduct(weight, x[i]) < 0:\n",
    "            y_scores_pre.append(-1)\n",
    "        else:\n",
    "            y_scores_pre.append(1)\n",
    "    \n",
    "    y_true = np.array(y_true_pre)\n",
    "    y_scores = np.array(y_scores_pre)\n",
    "        \n",
    "    if evaluation_metric == 'auROC':\n",
    "        metric = roc_auc_score(y_true, y_scores)\n",
    "    elif evaluation_metric == 'AP':\n",
    "        metric = average_precision_score(y_true, y_scores)\n",
    "    return metric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_list = [0.000000001, 0.00000001, 0.0000001, 0.000001,0.00001, 0.0001, 0.001, 0.01, 0.1, 1,10, 100]\n",
    "auROC_list = []\n",
    "AP_list = []\n",
    "for regularizer in lam_list:\n",
    "    weight = pegasos_fast(train_df,max_epoch=10, lam = regularizer)\n",
    "    auROC_metric = evaluate_model(validation_df,weight,'auROC')\n",
    "    auROC_list.append(auROC_metric)\n",
    "    AP_metric = evaluate_model(validation_df,weight,'AP')\n",
    "    AP_list.append(AP_metric)\n",
    "print('Table of each Lambda and its Evaluation Metric')\n",
    "for lam, auROC, AP in zip(lam_list, auROC_list, AP_list):\n",
    "    print(lam, auROC, AP)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Imbalanced Data too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
